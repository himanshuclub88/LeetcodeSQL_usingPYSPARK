{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f2ef0c272e6c920",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# [1378. Replace Employee ID With The Unique Identifier](https://leetcode.com/problems/replace-employee-id-with-the-unique-identifier/description/?envType=study-plan-v2&envId=top-sql-50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8833a5b06fff9667",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Table: Employees\n",
    "<pre>\n",
    "+---------------+---------+\n",
    "| Column Name   | Type    |\n",
    "+---------------+---------+\n",
    "| id            | int     |\n",
    "| name          | varchar |\n",
    "+---------------+---------+</pre>\n",
    "id is the primary key (column with unique values) for this table.\n",
    "Each row of this table contains the id and the name of an employee in a company.\n",
    " \n",
    "\n",
    "Table: EmployeeUNI\n",
    "<pre>\n",
    "+---------------+---------+\n",
    "| Column Name   | Type    |\n",
    "+---------------+---------+\n",
    "| id            | int     |\n",
    "| unique_id     | int     |\n",
    "+---------------+---------+</pre>\n",
    "(id, unique_id) is the primary key (combination of columns with unique values) for this table.\n",
    "Each row of this table contains the id and the corresponding unique id of an employee in the company.\n",
    " \n",
    "\n",
    "Write a solution to show the unique ID of each user, If a user does not have a unique ID replace just show null.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Employees table:\n",
    "<pre>+----+----------+\n",
    "| id | name     |\n",
    "+----+----------+\n",
    "| 1  | Alice    |\n",
    "| 7  | Bob      |\n",
    "| 11 | Meir     |\n",
    "| 90 | Winston  |\n",
    "| 3  | Jonathan |\n",
    "+----+----------+</pre>\n",
    "EmployeeUNI table:\n",
    "<pre>+----+-----------+\n",
    "| id | unique_id |\n",
    "+----+-----------+\n",
    "| 3  | 1         |\n",
    "| 11 | 2         |\n",
    "| 90 | 3         |\n",
    "+----+-----------+</pre>\n",
    "Output: \n",
    "<pre>+-----------+----------+\n",
    "| unique_id | name     |\n",
    "+-----------+----------+\n",
    "| null      | Alice    |\n",
    "| null      | Bob      |\n",
    "| 2         | Meir     |\n",
    "| 3         | Winston  |\n",
    "| 1         | Jonathan |\n",
    "+-----------+----------+</pre>\n",
    "Explanation: \n",
    "Alice and Bob do not have a unique ID, We will show null instead.\n",
    "The unique ID of Meir is 2.\n",
    "The unique ID of Winston is 3.\n",
    "The unique ID of Jonathan is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9858a8e925b70a5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T18:55:50.805514300Z",
     "start_time": "2023-11-05T18:55:50.263464800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Pandas Schema\n",
    "import pandas as pd\n",
    "\n",
    "data = [[1, 'Alice'], [7, 'Bob'], [11, 'Meir'], [90, 'Winston'], [3, 'Jonathan']]\n",
    "employees = pd.DataFrame(data, columns=['id', 'name']).astype({'id':'int64', 'name':'object'})\n",
    "data = [[3, 1], [11, 2], [90, 3]]\n",
    "employee_uni = pd.DataFrame(data, columns=['id', 'unique_id']).astype({'id':'int64', 'unique_id':'int64'})\n",
    "#to pyspark schema\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "employees_df = spark.createDataFrame(employees)\n",
    "employee_uni_df = spark.createDataFrame(employee_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "176a4a8e320f176e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T18:56:09.473630200Z",
     "start_time": "2023-11-05T18:56:08.262775700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "|id |name    |\n",
      "+---+--------+\n",
      "|1  |Alice   |\n",
      "|7  |Bob     |\n",
      "|11 |Meir    |\n",
      "|90 |Winston |\n",
      "|3  |Jonathan|\n",
      "+---+--------+\n",
      "\n",
      "+---+---------+\n",
      "|id |unique_id|\n",
      "+---+---------+\n",
      "|3  |1        |\n",
      "|11 |2        |\n",
      "|90 |3        |\n",
      "+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.show(truncate=False)\n",
    "employee_uni_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c265c30edfbf76a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T18:56:11.918252300Z",
     "start_time": "2023-11-05T18:56:09.468227100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|unique_id|    name|\n",
      "+---------+--------+\n",
      "|     NULL|   Alice|\n",
      "|     NULL|     Bob|\n",
      "|        2|    Meir|\n",
      "|        3| Winston|\n",
      "|        1|Jonathan|\n",
      "+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# in spark Dafaframe\n",
    "\n",
    "employees_df.join(employee_uni_df, ['id'] ,'left').select('unique_id','name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f827a905c69a79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T18:56:13.707262300Z",
     "start_time": "2023-11-05T18:56:11.922433300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|unique_id|    name|\n",
      "+---------+--------+\n",
      "|     NULL|   Alice|\n",
      "|     NULL|     Bob|\n",
      "|        2|    Meir|\n",
      "|        3| Winston|\n",
      "|        1|Jonathan|\n",
      "+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# in spark SQL\n",
    "\n",
    "employees_df.createOrReplaceTempView('employees')\n",
    "employee_uni_df.createOrReplaceTempView('employee_uni')\n",
    "\n",
    "spark.sql('''\n",
    "select unique_id, name\n",
    "from employees\n",
    "left join employee_uni \n",
    "on employees.id = employee_uni.id;\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f51ccc802d24c64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T18:56:14.152656600Z",
     "start_time": "2023-11-05T18:56:13.453788100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405f83bfcf69bb8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T18:56:14.207768800Z",
     "start_time": "2023-11-05T18:56:14.156848200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
