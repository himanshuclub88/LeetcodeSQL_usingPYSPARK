{"cells":[{"cell_type":"markdown","source":["# [1789. Primary Department for Each Employee](https://leetcode.com/problems/primary-department-for-each-employee/description/?envType=study-plan-v2&envId=top-sql-50)"],"metadata":{"collapsed":false,"id":"4441252f33de6a29"},"id":"4441252f33de6a29"},{"cell_type":"markdown","source":["Table: Employee\n","\n","<pre>+---------------+---------+\n","| Column Name   |  Type   |\n","+---------------+---------+\n","| employee_id   | int     |\n","| department_id | int     |\n","| primary_flag  | varchar |\n","+---------------+---------+</pre>\n","(employee_id, department_id) is the primary key (combination of columns with unique values) for this table.\n","employee_id is the id of the employee.\n","department_id is the id of the department to which the employee belongs.\n","primary_flag is an ENUM (category) of type ('Y', 'N'). If the flag is 'Y', the department is the primary department for the employee. If the flag is 'N', the department is not the primary.\n","\n","\n","Employees can belong to multiple departments. When the employee joins other departments, they need to decide which department is their primary department. Note that when an employee belongs to only one department, their primary column is 'N'.\n","\n","Write a solution to report all the employees with their primary department. For employees who belong to one department, report their only department.\n","\n","Return the result table in any order.\n","\n","The result format is in the following example.\n","\n","\n","\n","Example 1:\n","\n","Input:\n","Employee table:\n","<pre>+-------------+---------------+--------------+\n","| employee_id | department_id | primary_flag |\n","+-------------+---------------+--------------+\n","| 1           | 1             | N            |\n","| 2           | 1             | Y            |\n","| 2           | 2             | N            |\n","| 3           | 3             | N            |\n","| 4           | 2             | N            |\n","| 4           | 3             | Y            |\n","| 4           | 4             | N            |\n","+-------------+---------------+--------------+</pre>\n","Output:\n","<pre>+-------------+---------------+\n","| employee_id | department_id |\n","+-------------+---------------+\n","| 1           | 1             |\n","| 2           | 1             |\n","| 3           | 3             |\n","| 4           | 3             |\n","+-------------+---------------+</pre>\n","Explanation:\n","- The Primary department for employee 1 is 1.\n","- The Primary department for employee 2 is 1.\n","- The Primary department for employee 3 is 3.\n","- The Primary department for employee 4 is 3."],"metadata":{"collapsed":false,"id":"8f9efff1c89cd24a"},"id":"8f9efff1c89cd24a"},{"cell_type":"code","execution_count":4,"outputs":[],"source":["# pandas schema\n","\n","import pandas as pd\n","\n","data = [['1', '1', 'N'], ['2', '1', 'Y'], ['2', '2', 'N'], ['3', '3', 'N'], ['4', '2', 'N'], ['4', '3', 'Y'],\n","        ['4', '4', 'N']]\n","employee = pd.DataFrame(data, columns=['employee_id', 'department_id', 'primary_flag']).astype(\n","    {'employee_id': 'Int64', 'department_id': 'Int64', 'primary_flag': 'object'})\n","# to pyspark schema\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import *\n","\n","spark = SparkSession.builder.getOrCreate()\n","\n","employee_df = spark.createDataFrame(employee)\n"],"metadata":{"ExecuteTime":{"end_time":"2023-11-05T19:18:54.127632Z","start_time":"2023-11-05T19:18:54.124062600Z"},"id":"de4b0cd6712aa24b","executionInfo":{"status":"ok","timestamp":1743246227443,"user_tz":-330,"elapsed":16700,"user":{"displayName":"Himanshu Singh","userId":"04013931203390313061"}}},"id":"de4b0cd6712aa24b"},{"cell_type":"code","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+-------------+------------+\n","|employee_id|department_id|primary_flag|\n","+-----------+-------------+------------+\n","|          1|            1|           N|\n","|          2|            1|           Y|\n","|          2|            2|           N|\n","|          3|            3|           N|\n","|          4|            2|           N|\n","|          4|            3|           Y|\n","|          4|            4|           N|\n","+-----------+-------------+------------+\n","\n"]}],"source":["employee_df.show()"],"metadata":{"ExecuteTime":{"end_time":"2023-11-05T19:18:56.176367100Z","start_time":"2023-11-05T19:18:54.135377400Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"684be64bbd2434b5","executionInfo":{"status":"ok","timestamp":1743246236876,"user_tz":-330,"elapsed":9422,"user":{"displayName":"Himanshu Singh","userId":"04013931203390313061"}},"outputId":"f329620a-cd80-40de-967e-005f247923db"},"id":"684be64bbd2434b5"},{"cell_type":"code","execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+-------------+\n","|employee_id|department_id|\n","+-----------+-------------+\n","|          1|            1|\n","|          2|            1|\n","|          3|            3|\n","|          4|            3|\n","+-----------+-------------+\n","\n"]}],"source":["from pyspark.sql import window\n","\n","# In pyspark dataframe\n","window_partion = Window.partitionBy('employee_id')\n","\n","employee_df \\\n","    .withColumn('cnt',count('department_id').over(window_partion))\\\n","    .where(\"cnt=1 or primary_flag='Y'\" )\\\n","    .select('employee_id','department_id')\\\n","    .show()"],"metadata":{"ExecuteTime":{"end_time":"2023-11-05T19:18:56.931962100Z","start_time":"2023-11-05T19:18:56.172805800Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"7cda840b1b09dbba","executionInfo":{"status":"ok","timestamp":1743247066905,"user_tz":-330,"elapsed":8,"user":{"displayName":"Himanshu Singh","userId":"04013931203390313061"}},"outputId":"f15c9cc5-9f0c-4065-a191-d86b2d3b5922"},"id":"7cda840b1b09dbba"},{"cell_type":"code","execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+-------------+\n","|employee_id|department_id|\n","+-----------+-------------+\n","|          1|            1|\n","|          2|            1|\n","|          3|            3|\n","|          4|            3|\n","+-----------+-------------+\n","\n"]}],"source":["# In spark SQL\n","\n","employee_df.createOrReplaceTempView('employee')\n","\n","spark.sql('''\n","\n","select employee_id,department_id\n","from\n","(select employee_id,department_id,primary_flag,\n","count(department_id) over(partition by employee_id) as cnt\n","from employee) x\n","\n","where cnt=1 or primary_flag='Y'\n","\n","''').show()"],"metadata":{"ExecuteTime":{"end_time":"2023-11-05T19:18:57.741348900Z","start_time":"2023-11-05T19:18:56.927446900Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"43ffbe6d56d2ce4e","executionInfo":{"status":"ok","timestamp":1743247075006,"user_tz":-330,"elapsed":888,"user":{"displayName":"Himanshu Singh","userId":"04013931203390313061"}},"outputId":"e69deb09-9d80-4c46-ff7c-cfb57639a4f0"},"id":"43ffbe6d56d2ce4e"},{"cell_type":"code","execution_count":null,"outputs":[],"source":["spark.stop()"],"metadata":{"ExecuteTime":{"end_time":"2023-11-05T19:18:58.648389400Z","start_time":"2023-11-05T19:18:57.728217300Z"},"id":"3a6f4e418a525380"},"id":"3a6f4e418a525380"},{"cell_type":"code","execution_count":null,"outputs":[],"source":[],"metadata":{"ExecuteTime":{"end_time":"2023-11-05T19:18:58.718935700Z","start_time":"2023-11-05T19:18:58.651037Z"},"id":"56e61d8cabbb26c0"},"id":"56e61d8cabbb26c0"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}